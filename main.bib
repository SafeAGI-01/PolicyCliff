
@book{AliprantisBorder2006InfiniteDimAnalysis,
  author    = {Aliprantis, Charalambos D. and Border, Kim C.},
  title     = {Infinite Dimensional Analysis: A Hitchhiker's Guide},
  year      = {2006},
  edition   = {3rd},
  publisher = {Springer},
  address   = {Berlin, Heidelberg}
}


@book{sutton1998reinforcement,
  title={Reinforcement learning: An introduction},
  author={Sutton, Richard S and Barto, Andrew G},
  volume={1},
  number={1},
  year={1998},
  publisher={MIT press Cambridge}
}

@book{munkres2000topology,
  author    = {Munkres, James R.},
  title     = {Topology},
  edition   = {2nd},
  year      = {2000},
  publisher = {Prentice Hall},
  address   = {Upper Saddle Rivers, NJ}
}


%%%%%%%%%%%%%%%% AI Models %%%%%%%%%%%%%%%%%

@article{openai2024o1,
  author       = {{OpenAI}},
  title        = {OpenAI o1 System Card},
  howpublished = {\url{https://cdn.openai.com/o1-system-card-20241205.pdf}},
  note         = {Model card},
  month        = dec,
  year         = {2024}
}

@article{openai2025o3o4,
  author       = {{OpenAI}},
  title        = {OpenAI o3 and o4-mini System Card},
  howpublished = {\url{https://cdn.openai.com/pdf/2221c875-02dc-4789-800b-e7758f3722c1/o3-and-o4-mini-system-card.pdf}},
  note         = {Model card},
  month        = apr,
  year         = {2025}
}

@article{gemini2025frontier,
  author       = {{Gemini Team, Google}},
  title        = {Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities},
  howpublished = {\url{https://storage.googleapis.com/deepmind-media/gemini/gemini_v2_5_report.pdf}},
  institution  = {Google DeepMind},
  year         = {2025},
  month        = jun
}

@article{anthropic2025claude,
  author       = {{Anthropic}},
  title        = {System Card: Claude Opus 4 \& Claude Sonnet 4},
  howpublished = {\url{https://www-cdn.anthropic.com/6be99a52cb68eb70eb9572b4cafad13df32ed995.pdf}},
  month        = may,
  year         = {2025},
  note         = {System card documentation}
}

@article{guo2025deepseek,
  title={Deepseek-r1: Incentivizing reasoning capability in llms via reinforcement learning},
  author={Guo, Daya and Yang, Dejian and Zhang, Haowei and Song, Junxiao and Zhang, Ruoyu and Xu, Runxin and Zhu, Qihao and Ma, Shirong and Wang, Peiyi and Bi, Xiao and others},
  journal={arXiv preprint arXiv:2501.12948},
  year={2025}
}

@article{yang2025qwen3,
  title={Qwen3 technical report},
  author={Yang, An and Li, Anfeng and Yang, Baosong and Zhang, Beichen and Hui, Binyuan and Zheng, Bo and Yu, Bowen and Gao, Chang and Huang, Chengen and Lv, Chenxu and others},
  journal={arXiv preprint arXiv:2505.09388},
  year={2025}
}

%%%%%%%%%%%%%%%%%%%%%% AlphaGo %%%%%%%%%%%%%%%%%%%%%%%

% AlphaGo 
@article{silver2016mastering,
  title={Mastering the game of Go with deep neural networks and tree search},
  author={Silver, David and Huang, Aja and Maddison, Chris J and Guez, Arthur and Sifre, Laurent and Van Den Driessche, George and Schrittwieser, Julian and Antonoglou, Ioannis and Panneershelvam, Veda and Lanctot, Marc and others},
  journal={Nature},
  volume={529},
  number={7587},
  pages={484--489},
  year={2016},
  publisher={Nature Publishing Group}
}

% AlphaGo Zero
@article{silver2017mastering,
  title={Mastering the game of go without human knowledge},
  author={Silver, David and Schrittwieser, Julian and Simonyan, Karen and Antonoglou, Ioannis and Huang, Aja and Guez, Arthur and Hubert, Thomas and Baker, Lucas and Lai, Matthew and Bolton, Adrian and others},
  journal={Nature},
  volume={550},
  number={7676},
  pages={354--359},
  year={2017},
  publisher={Nature Publishing Group UK London}
}

% AlphaZero
@article{silver2018general,
  title={A general reinforcement learning algorithm that masters chess, shogi, and Go through self-play},
  author={Silver, David and Hubert, Thomas and Schrittwieser, Julian and Antonoglou, Ioannis and Lai, Matthew and Guez, Arthur and Lanctot, Marc and Sifre, Laurent and Kumaran, Dharshan and Graepel, Thore and others},
  journal={Science},
  volume={362},
  number={6419},
  pages={1140--1144},
  year={2018},
  publisher={American Association for the Advancement of Science}
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

@article{wang2025persona,
  title={Persona Features Control Emergent Misalignment},
  author={Wang, Miles and Dupré la Tour, Tom and Watkins, Olivia and Makelov, Alex and Chi, Ryan A. and Miserendino, Samuel and Heidecke, Johannes and Patwardhan, Tejal and Mossing, Dan},
  journal={OpenAI},
  year={2025}
}

@article{baker2025monitoring,
  title={Monitoring reasoning models for misbehavior and the risks of promoting obfuscation},
  author={Baker, Bowen and Huizinga, Joost and Gao, Leo and Dou, Zehao and Guan, Melody Y and Madry, Aleksander and Zaremba, Wojciech and Pachocki, Jakub and Farhi, David},
  journal={arXiv preprint arXiv:2503.11926},
  year={2025}
}

@article{chen2025reasoning,
  title={Reasoning Models Don't Always Say What They Think},
  author={Chen, Yanda and Benton, Joe and Radhakrishnan, Ansh and Uesato, Jonathan and Denison, Carson and Schulman, John and Somani, Arushi and Hase, Peter and Wagner, Misha and Roger, Fabien and others},
  journal={arXiv preprint arXiv:2505.05410},
  year={2025}
}

@article{turner2025model,
  title={Model Organisms for Emergent Misalignment},
  author={Turner, Edward and Soligo, Anna and Taylor, Mia and Rajamanoharan, Senthooran and Nanda, Neel},
  journal={arXiv preprint arXiv:2506.11613},
  year={2025}
}

@article{christiano2017deep,
  title={Deep reinforcement learning from human preferences},
  author={Christiano, Paul F and Leike, Jan and Brown, Tom and Martic, Miljan and Legg, Shane and Amodei, Dario},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@article{skalse2022defining,
  title={Defining and characterizing reward hacking},
  author={Skalse, Joar and Howe, Nikolaus and Krasheninnikov, Dmitrii and Krueger, David},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={9460--9471},
  year={2022}
}

@article{openai2025sycophancy,
  author       = {{OpenAI}},
  title        = {Sycophancy in GPT-4o: What Happened and What We’re Doing About It},
  howpublished = {\url{https://openai.com/index/sycophancy-in-gpt-4o/}},
  year         = {2025}
}

@article{openai2025expanding,
  author       = {{OpenAI}},
  title        = {Expanding on What We Missed with Sycophancy},
  howpublished = {\url{https://openai.com/index/expanding-on-sycophancy/}},
  year         = {2025}
}

@article{fu2025scaling,
  title={Scaling reasoning, losing control: Evaluating instruction following in large reasoning models},
  author={Fu, Tingchen and Gu, Jiawei and Li, Yafu and Qu, Xiaoye and Cheng, Yu},
  journal={arXiv preprint arXiv:2505.14810},
  year={2025}
}

% RLHF
@article{ouyang2022training,
  title={Training language models to follow instructions with human feedback},
  author={Ouyang, Long and Wu, Jeffrey and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and others},
  journal={Advances in neural information processing systems},
  volume={35},
  pages={27730--27744},
  year={2022}
}

% Constitutional AI
@article{bai2022constitutional,
  title={Constitutional ai: Harmlessness from ai feedback},
  author={Bai, Yuntao and Kadavath, Saurav and Kundu, Sandipan and Askell, Amanda and Kernion, Jackson and Jones, Andy and Chen, Anna and Goldie, Anna and Mirhoseini, Azalia and McKinnon, Cameron and others},
  journal={arXiv preprint arXiv:2212.08073},
  year={2022}
}

%RLAIF
@article{lee2023rlaif,
  title={RLAIF: Scaling reinforcement learning from human feedback with ai feedback},
  author={Lee, Harrison and Phatale, Samrat and Mansoor, Hassan and Lu, Kellie Ren and Mesnard, Thomas and Ferret, Johan and Bishop, Colton and Hall, Ethan and Carbune, Victor and Rastogi, Abhinav},
  year={2023}
}

% RLVR
@article{wang2025reinforcement,
  title={Reinforcement learning for reasoning in large language models with one training example},
  author={Wang, Yiping and Yang, Qing and Zeng, Zhiyuan and Ren, Liliang and Liu, Liyuan and Peng, Baolin and Cheng, Hao and He, Xuehai and Wang, Kuan and Gao, Jianfeng and others},
  journal={arXiv preprint arXiv:2504.20571},
  year={2025}
}

% efficient reasoning
@article{sui2025stop,
  title={Stop overthinking: A survey on efficient reasoning for large language models},
  author={Sui, Yang and Chuang, Yu-Neng and Wang, Guanchu and Zhang, Jiamu and Zhang, Tianyi and Yuan, Jiayi and Liu, Hongyi and Wen, Andrew and Zhong, Shaochen and Chen, Hanjie and others},
  journal={arXiv preprint arXiv:2503.16419},
  year={2025}
}

% efficient reasoning
@article{chen2025towards,
  title={Towards reasoning era: A survey of long chain-of-thought for reasoning large language models},
  author={Chen, Qiguang and Qin, Libo and Liu, Jinhao and Peng, Dengyun and Guan, Jiannan and Wang, Peng and Hu, Mengkang and Zhou, Yuhang and Gao, Te and Che, Wanxiang},
  journal={arXiv preprint arXiv:2503.09567},
  year={2025}
}

% efficient reasoning
@article{qu2025survey,
  title={A survey of efficient reasoning for large reasoning models: Language, multimodality, and beyond},
  author={Qu, Xiaoye and Li, Yafu and Su, Zhaochen and Sun, Weigao and Yan, Jianhao and Liu, Dongrui and Cui, Ganqu and Liu, Daizong and Liang, Shuxian and He, Junxian and others},
  journal={arXiv preprint arXiv:2503.21614},
  year={2025}
}

% Deliberative alignment
@article{guan2024deliberative,
  title={Deliberative alignment: Reasoning enables safer language models},
  author={Guan, Melody Y and Joglekar, Manas and Wallace, Eric and Jain, Saachi and Barak, Boaz and Helyar, Alec and Dias, Rachel and Vallone, Andrea and Ren, Hongyu and Wei, Jason and others},
  journal={arXiv preprint arXiv:2412.16339},
  year={2024}
}

% L1 efficient reasoning
@article{aggarwal2025l1,
  title={L1: Controlling how long a reasoning model thinks with reinforcement learning},
  author={Aggarwal, Pranjal and Welleck, Sean},
  journal={arXiv preprint arXiv:2503.04697},
  year={2025}
}

% efficient reasoning
@article{arora2025training,
  title={Training Language Models to Reason Efficiently},
  author={Arora, Daman and Zanette, Andrea},
  journal={arXiv preprint arXiv:2502.04463},
  year={2025}
}

% Reward Hacking
@article{weng2024rewardhack,
  title   = "Reward Hacking in Reinforcement Learning",
  author  = "Weng, Lilian",
  journal = "lilianweng.github.io",
  year    = "2024",
  month   = "Nov",
  url     = "https://lilianweng.github.io/posts/2024-11-28-reward-hacking/"
}

% RLHF hacking
@article{wen2024language,
  title={Language models learn to mislead humans via RLHF},
  author={Wen, Jiaxin and Zhong, Ruiqi and Khan, Akbir and Perez, Ethan and Steinhardt, Jacob and Huang, Minlie and Bowman, Samuel R and He, He and Feng, Shi},
  journal={arXiv preprint arXiv:2409.12822},
  year={2024}
}

% the era of experience
@article{silver2025welcome,
  title={Welcome to the era of experience},
  author={Silver, David and Sutton, Richard S},
  journal={Google AI},
  volume={1},
  year={2025}
}

% MoDoMoDo
@article{liang2025modomodo,
  title={MoDoMoDo: Multi-Domain Data Mixtures for Multimodal LLM Reinforcement Learning},
  author={Liang, Yiqing and Qiu, Jielin and Ding, Wenhao and Liu, Zuxin and Tompkin, James and Xu, Mengdi and Xia, Mengzhou and Tu, Zhengzhong and Shi, Laixi and Zhu, Jiacheng},
  journal={arXiv preprint arXiv:2505.24871},
  year={2025}
}

% Cross-Domain
@article{cheng2025revisiting,
  title={Revisiting Reinforcement Learning for LLM Reasoning from A Cross-Domain Perspective},
  author={Cheng, Zhoujun and Hao, Shibo and Liu, Tianyang and Zhou, Fan and Xie, Yutao and Yao, Feng and Bian, Yuexin and Zhuang, Yonghao and Dey, Nilabjo and Zha, Yuheng and others},
  journal={arXiv preprint arXiv:2506.14965},
  year={2025}
}

% Cross-Domain, RLVR
@article{su2025crossing,
  title={Crossing the Reward Bridge: Expanding RL with Verifiable Rewards Across Diverse Domains},
  author={Su, Yi and Yu, Dian and Song, Linfeng and Li, Juntao and Mi, Haitao and Tu, Zhaopeng and Zhang, Min and Yu, Dong},
  journal={arXiv preprint arXiv:2503.23829},
  year={2025}
}


@inproceedings{lecarpentier2021lipschitz,
  title={Lipschitz lifelong reinforcement learning},
  author={Lecarpentier, Erwan and Abel, David and Asadi, Kavosh and Jinnai, Yuu and Rachelson, Emmanuel and Littman, Michael L},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={35},
  number={9},
  pages={8270--8278},
  year={2021}
}


@book{berge1963topological,
  title={Topological spaces: Including a treatment of multi-valued functions, vector spaces and convexity},
  author={Berge, Claude},
  year={1963},
  publisher={Oliver \& Boyd}
}

% entropy regularization
@inproceedings{haarnoja2018soft,
  title={Soft actor-critic: Off-policy maximum entropy deep reinforcement learning with a stochastic actor},
  author={Haarnoja, Tuomas and Zhou, Aurick and Abbeel, Pieter and Levine, Sergey},
  booktitle={International conference on machine learning},
  pages={1861--1870},
  year={2018},
  organization={Pmlr}
}

% entropy regularization
@inproceedings{geist2019theory,
  title={A theory of regularized markov decision processes},
  author={Geist, Matthieu and Scherrer, Bruno and Pietquin, Olivier},
  booktitle={International conference on machine learning},
  pages={2160--2169},
  year={2019},
  organization={PMLR}
}

% OpenRLHF
@article{hu2024openrlhf,
  title={OpenRLHF: An Easy-to-use, Scalable and High-performance RLHF Framework},
  author={Jian Hu and Xibin Wu and Zilin Zhu and Xianyu and Weixun Wang and Dehao Zhang and Yu Cao},
  journal={arXiv preprint arXiv:2405.11143},
  year={2024}
}

% VeRL
@article{sheng2024hybridflow,
  title   = {HybridFlow: A Flexible and Efficient RLHF Framework},
  author  = {Guangming Sheng and Chi Zhang and Zilingfeng Ye and Xibin Wu and Wang Zhang and Ru Zhang and Yanghua Peng and Haibin Lin and Chuan Wu},
  year    = {2024},
  journal = {arXiv preprint arXiv: 2409.19256}
}

% Qwen2.5-VL
@article{bai2025qwen25,
  title={Qwen2.5-VL technical report},
  author={Bai, Shuai and Chen, Keqin and Liu, Xuejing and Wang, Jialin and Ge, Wenbin and Song, Sibo and Dang, Kai and Wang, Peng and Wang, Shijie and Tang, Jun and others},
  journal={arXiv preprint arXiv:2502.13923},
  year={2025}
}

@book{puterman2005markov,
  title={Markov decision processes: discrete stochastic dynamic programming},
  author={Puterman, Martin L},
  year={2005},
  publisher={John Wiley \& Sons}
}

@article{wirth2017survey,
  title={A survey of preference-based reinforcement learning methods},
  author={Wirth, Christian and Akrour, Riad and Neumann, Gerhard and F{\"u}rnkranz, Johannes},
  journal={Journal of Machine Learning Research},
  volume={18},
  number={136},
  pages={1--46},
  year={2017}
}

@inproceedings{wang2020reinforcement,
  title={Reinforcement learning with perturbed rewards},
  author={Wang, Jingkang and Liu, Yang and Li, Bo},
  booktitle={Proceedings of the AAAI conference on artificial intelligence},
  volume={34},
  number={04},
  pages={6202--6209},
  year={2020}
}

@article{banihashem2021defense,
  title={Defense against reward poisoning attacks in reinforcement learning},
  author={Banihashem, Kiarash and Singla, Adish and Radanovic, Goran},
  journal={arXiv preprint arXiv:2102.05776},
  year={2021}
}

@article{gupta2023behavior,
  title={Behavior alignment via reward function optimization},
  author={Gupta, Dhawal and Chandak, Yash and Jordan, Scott and Thomas, Philip S and C da Silva, Bruno},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  pages={52759--52791},
  year={2023}
}

@article{schulman2017proximal,
  title={Proximal policy optimization algorithms},
  author={Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
  journal={arXiv preprint arXiv:1707.06347},
  year={2017}
}

@article{roijers2013survey,
  title={A survey of multi-objective sequential decision-making},
  author={Roijers, Diederik M and Vamplew, Peter and Whiteson, Shimon and Dazeley, Richard},
  journal={Journal of Artificial Intelligence Research},
  volume={48},
  pages={67--113},
  year={2013}
}
